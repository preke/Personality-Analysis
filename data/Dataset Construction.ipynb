{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>characters</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>scene_id</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>single_text</th>\n",
       "      <th>full</th>\n",
       "      <th>single_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Phoebe Buffay</td>\n",
       "      <td>[[Monica Geller,  Well, what happened?], [Phoe...</td>\n",
       "      <td>01_e12_c08(0)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>speaker0 Well, he came in for a massage, and ...</td>\n",
       "      <td>speaker1 Well, what happened? speaker0 Well, ...</td>\n",
       "      <td>speaker0 Well, he came in for a massage, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Rachel</td>\n",
       "      <td>[[Monica,  (to Chandler) Anything but stew.], ...</td>\n",
       "      <td>03_e24_c04(0)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>speaker0 Yeah. speaker0 Oh, ah with who?</td>\n",
       "      <td>speaker1 (to Chandler) Anything but stew. spe...</td>\n",
       "      <td>speaker0 Yeah. speaker0 Oh, ah with who? spea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Eddie</td>\n",
       "      <td>[[Eddie,  Hey pal.], [Chandler Bing,  Ahhhh-ga...</td>\n",
       "      <td>02_e19_c06(0)</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>speaker0 Hey pal. speaker1 Ahhhh-gaaaahhh. Ed...</td>\n",
       "      <td>speaker0 Hey pal. speaker1 Ahhhh-gaaaahhh. Ed...</td>\n",
       "      <td>speaker0 Hey pal. speaker1 Ahhhh-gaaaahhh. Ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Phoebe Buffay</td>\n",
       "      <td>[[Chandler Bing,  Oh no no no, she's a total w...</td>\n",
       "      <td>02_e12_c05(0)</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>speaker0 No, uh-uh, I'm just, I'm nervous. So...</td>\n",
       "      <td>speaker1 Oh no no no, she's a total wack job....</td>\n",
       "      <td>speaker0 No, uh-uh, I'm just, I'm nervous. So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Chandler Bing</td>\n",
       "      <td>[[Joey Tribbiani,  Uh, hey, Dr. Greene, why do...</td>\n",
       "      <td>02_e22_c03(1)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>speaker0 Yes because uh, you look so young. s...</td>\n",
       "      <td>speaker1 Uh, hey, Dr. Greene, why don't you c...</td>\n",
       "      <td>speaker0 Yes because uh, you look so young. s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     characters  \\\n",
       "0           0  Phoebe Buffay   \n",
       "1           1         Rachel   \n",
       "2           2          Eddie   \n",
       "3           3  Phoebe Buffay   \n",
       "4           4  Chandler Bing   \n",
       "\n",
       "                                            raw_text        scene_id   cAGR  \\\n",
       "0  [[Monica Geller,  Well, what happened?], [Phoe...  01_e12_c08(0)   False   \n",
       "1  [[Monica,  (to Chandler) Anything but stew.], ...  03_e24_c04(0)   False   \n",
       "2  [[Eddie,  Hey pal.], [Chandler Bing,  Ahhhh-ga...  02_e19_c06(0)    True   \n",
       "3  [[Chandler Bing,  Oh no no no, she's a total w...  02_e12_c05(0)    True   \n",
       "4  [[Joey Tribbiani,  Uh, hey, Dr. Greene, why do...  02_e22_c03(1)   False   \n",
       "\n",
       "    cCON   cEXT   cOPN   cNEU  \\\n",
       "0  False   True   True   True   \n",
       "1  False   True   True  False   \n",
       "2   True   True   True   True   \n",
       "3  False   True   True   True   \n",
       "4  False  False  False  False   \n",
       "\n",
       "                                         single_text  \\\n",
       "0   speaker0 Well, he came in for a massage, and ...   \n",
       "1           speaker0 Yeah. speaker0 Oh, ah with who?   \n",
       "2   speaker0 Hey pal. speaker1 Ahhhh-gaaaahhh. Ed...   \n",
       "3   speaker0 No, uh-uh, I'm just, I'm nervous. So...   \n",
       "4   speaker0 Yes because uh, you look so young. s...   \n",
       "\n",
       "                                                full  \\\n",
       "0   speaker1 Well, what happened? speaker0 Well, ...   \n",
       "1   speaker1 (to Chandler) Anything but stew. spe...   \n",
       "2   speaker0 Hey pal. speaker1 Ahhhh-gaaaahhh. Ed...   \n",
       "3   speaker1 Oh no no no, she's a total wack job....   \n",
       "4   speaker1 Uh, hey, Dr. Greene, why don't you c...   \n",
       "\n",
       "                                      single_context  \n",
       "0   speaker0 Well, he came in for a massage, and ...  \n",
       "1   speaker0 Yeah. speaker0 Oh, ah with who? spea...  \n",
       "2   speaker0 Hey pal. speaker1 Ahhhh-gaaaahhh. Ed...  \n",
       "3   speaker0 No, uh-uh, I'm just, I'm nervous. So...  \n",
       "4   speaker0 Yes because uh, you look so young. s...  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('friends-personality.csv')\n",
    "\n",
    "# df['character'] = df['character'].apply(lambda x: x.split()[0] if (x != 'Phoebe Sr.') else x)\n",
    "df['raw_text'] = df['raw_text'].apply(lambda x: [[i.split('</b>:')[0].replace('<b>', ''), i.split('</b>:')[1]] for i in x.split('<br>') if \"</b>:\" in i ])\n",
    "\n",
    "\n",
    "# use main role or not...\n",
    "\n",
    "# main_roles = ['Chandler', 'Monica', 'Phoebe', 'Ross', 'Rachel', 'Joey']\n",
    "# df = df[df['character'].isin(main_roles)]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGR</th>\n",
       "      <th>CON</th>\n",
       "      <th>EXT</th>\n",
       "      <th>OPN</th>\n",
       "      <th>NEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>405</td>\n",
       "      <td>381</td>\n",
       "      <td>399</td>\n",
       "      <td>462</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>306</td>\n",
       "      <td>330</td>\n",
       "      <td>312</td>\n",
       "      <td>249</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGR  CON  EXT  OPN  NEU\n",
       "0  405  381  399  462  379\n",
       "1  306  330  312  249  332"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df[['cAGR','cCON','cEXT','cOPN','cNEU']]\n",
    "df_counts = pd.DataFrame([])\n",
    "df_counts['AGR'] = df_labels['cAGR'].value_counts().reset_index()['cAGR']\n",
    "df_counts['CON'] = df_labels['cCON'].value_counts().reset_index()['cCON']\n",
    "df_counts['EXT'] = df_labels['cEXT'].value_counts().reset_index()['cEXT']\n",
    "df_counts['OPN'] = df_labels['cOPN'].value_counts().reset_index()['cOPN']\n",
    "df_counts['NEU'] = df_labels['cNEU'].value_counts().reset_index()['cNEU']\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jan</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jan</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Dentist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feb</td>\n",
       "      <td>200.0</td>\n",
       "      <td>Dentist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb</td>\n",
       "      <td>28.5</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mar</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mar</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mar</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mar</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Month  Amount Category\n",
       "0   Jan     5.0   Travel\n",
       "1   Jan    65.0     Food\n",
       "2   Jan    29.0  Dentist\n",
       "3   Feb   200.0  Dentist\n",
       "4   Feb    28.5     Food\n",
       "5   Mar    12.0   Travel\n",
       "6   Mar     4.0     Food\n",
       "7   Mar   100.0    Sport\n",
       "8   Mar    21.0    Sport"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'Month': ['Jan', 'Jan', 'Jan', 'Feb', 'Feb', 'Mar', 'Mar', 'Mar', 'Mar'], 'Amount': [5, 65, 29, 200, 28.5, 12, 4, 100, 21], 'Category': ['Travel', 'Food', 'Dentist', 'Dentist', 'Food', 'Travel', 'Food', 'Sport', 'Sport']}\n",
    "df_ = pd.DataFrame(d)\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib # 注意这个也要import一次\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize # import figsize\n",
    "\n",
    "import seaborn as sns\n",
    "# sns.set(style=\"white\")\n",
    "\n",
    "\n",
    "df_counts.index = (['False', 'True'])\n",
    "ax = df_counts.T.plot.bar(stacked=True, color=['#FC7459', '#DBEAFF'])\n",
    "# ax.color_palette(\"pastel\")\n",
    "# annotate the bars\n",
    "for i, rect in enumerate(ax.patches):\n",
    "    # Find where everything is located\n",
    "    height = rect.get_height()\n",
    "    width = rect.get_width()\n",
    "    x = rect.get_x()\n",
    "    y = rect.get_y()\n",
    "\n",
    "    # The height of the bar is the count value and can used as the label\n",
    "    label_text = f'{height:.0f}'\n",
    "\n",
    "    label_x = x + width / 2\n",
    "    label_y = y + height / 2\n",
    "\n",
    "    # don't include label if it's equivalently 0\n",
    "    if height > 0.001:\n",
    "        ax.text(label_x, label_y, label_text, ha='center', va='center', fontsize=12)\n",
    "\n",
    "ax.set_xticklabels(df_counts.columns, rotation=23, fontsize=12, fontstyle='oblique', fontweight='550')\n",
    "ax.legend(bbox_to_anchor=(0.75, 0.99), loc=0, borderaxespad=0.0)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(True)\n",
    "ax.spines['bottom'].set_visible(True)\n",
    "plt.savefig('plot123_2.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021406541056415426"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [0.659, 0.627, 0.639, 0.689, 0.643]\n",
    "import numpy as np\n",
    "np.std(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-247-b76b803d7184>:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_A['dialog_state'] = df_A.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_C['dialog_state'] = df_C.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_E['dialog_state'] = df_E.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_O['dialog_state'] = df_O.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_N['dialog_state'] = df_N.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_A['sent'] = df_A.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_C['sent'] = df_C.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_E['sent'] = df_E.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_O['sent'] = df_O.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:72: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_N['sent'] = df_N.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_A['utterance'] = df_A.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_C['utterance'] = df_C.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_E['utterance'] = df_E.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_O['utterance'] = df_O.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_N['utterance'] = df_N.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_A['context'] = df_A.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_C['context'] = df_C.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_E['context'] = df_E.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_O['context'] = df_O.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_N['context'] = df_N.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
      "<ipython-input-247-b76b803d7184>:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_A['labels'] = df_A['cAGR'].apply(lambda x: 1 if x is True else 0)\n",
      "<ipython-input-247-b76b803d7184>:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_C['labels'] = df_C['cCON'].apply(lambda x: 1 if x is True else 0)\n",
      "<ipython-input-247-b76b803d7184>:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_E['labels'] = df_E['cEXT'].apply(lambda x: 1 if x is True else 0)\n",
      "<ipython-input-247-b76b803d7184>:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_O['labels'] = df_O['cOPN'].apply(lambda x: 1 if x is True else 0)\n",
      "<ipython-input-247-b76b803d7184>:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_N['labels'] = df_N['cNEU'].apply(lambda x: 1 if x is True else 0)\n"
     ]
    }
   ],
   "source": [
    "def get_text_role(sent_list, role):\n",
    "    '''\n",
    "    Extract the utterances from the given role\n",
    "    '''\n",
    "    ans = \"\"\n",
    "    for i in sent_list:\n",
    "        ## if i[0].split(' ')[0] == role and i[0] != 'Phoebe Sr.':\n",
    "        if i[0] == role:\n",
    "            ans = ans + ' ' + i[1]\n",
    "    return ans\n",
    "\n",
    "def get_context_role(sent_list, role):\n",
    "    '''\n",
    "    Extract the utterances not from the given role\n",
    "    '''\n",
    "    ans = \"\"\n",
    "    for i in sent_list:\n",
    "        # if i[0].split(' ')[0] != role or i[0] == 'Phoebe Sr.':\n",
    "        if i[0] != role:\n",
    "            ans = ans + ' ' + i[1]\n",
    "    return ans\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "MAX_LEN   = 128\n",
    "\n",
    "\n",
    "def get_seg_id(sent_list, role):\n",
    "    '''\n",
    "    Generate the segment id for the whole sent\n",
    "    '''\n",
    "\n",
    "    ans = []\n",
    "   \n",
    "    for i in sent_list:\n",
    "        if i[0].split(' ')[0] != role:\n",
    "            # tmp = tokenizer.encode(i[1], add_special_tokens=True, max_length=MAX_LEN, pad_to_max_length=True)\n",
    "            ans.append(0)\n",
    "        else:\n",
    "            ans.append(1)\n",
    "\n",
    "\n",
    "    return ans\n",
    "\n",
    "def get_sent(sent_list, role):\n",
    "    '''\n",
    "    Obtain the whole sent\n",
    "    '''\n",
    "    \n",
    "    ans = \"\"\n",
    "    for i in sent_list:\n",
    "        ans = ans + i[1]\n",
    "    return ans\n",
    "\n",
    "df_A = df[['scene_id', 'raw_text', 'characters', 'cAGR']]\n",
    "df_C = df[['scene_id', 'raw_text', 'characters', 'cCON']]\n",
    "df_E = df[['scene_id', 'raw_text', 'characters', 'cEXT']]\n",
    "df_O = df[['scene_id', 'raw_text', 'characters', 'cOPN']]\n",
    "df_N = df[['scene_id', 'raw_text', 'characters', 'cNEU']]\n",
    "\n",
    "df_A['dialog_state'] = df_A.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
    "df_C['dialog_state'] = df_C.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
    "df_E['dialog_state'] = df_E.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
    "df_O['dialog_state'] = df_O.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
    "df_N['dialog_state'] = df_N.apply(lambda r: get_seg_id(r['raw_text'], r['characters']), axis=1)\n",
    "\n",
    "df_A['sent'] = df_A.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
    "df_C['sent'] = df_C.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
    "df_E['sent'] = df_E.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
    "df_O['sent'] = df_O.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
    "df_N['sent'] = df_N.apply(lambda r: get_sent(r['raw_text'], r['characters']), axis=1)\n",
    "\n",
    "df_A['utterance'] = df_A.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_C['utterance'] = df_C.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_E['utterance'] = df_E.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_O['utterance'] = df_O.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_N['utterance'] = df_N.apply(lambda r: get_text_role(r['raw_text'], r['characters']), axis=1)\n",
    "\n",
    "df_A['context'] = df_A.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_C['context'] = df_C.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_E['context'] = df_E.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_O['context'] = df_O.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
    "df_N['context'] = df_N.apply(lambda r: get_context_role(r['raw_text'], r['characters']), axis=1)\n",
    "\n",
    "df_A['labels'] = df_A['cAGR'].apply(lambda x: 1 if x is True else 0)\n",
    "df_C['labels'] = df_C['cCON'].apply(lambda x: 1 if x is True else 0)\n",
    "df_E['labels'] = df_E['cEXT'].apply(lambda x: 1 if x is True else 0)\n",
    "df_O['labels'] = df_O['cOPN'].apply(lambda x: 1 if x is True else 0)\n",
    "df_N['labels'] = df_N['cNEU'].apply(lambda x: 1 if x is True else 0)\n",
    "\n",
    "# df_A.to_csv('Friends_A.tsv', sep='\\t') \n",
    "# df_C.to_csv('Friends_C.tsv', sep='\\t')\n",
    "# df_E.to_csv('Friends_E.tsv', sep='\\t')\n",
    "# df_O.to_csv('Friends_O.tsv', sep='\\t')\n",
    "# df_N.to_csv('Friends_N.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "df_A.to_csv('Friends_A_whole.tsv', sep='\\t') \n",
    "df_C.to_csv('Friends_C_whole.tsv', sep='\\t')\n",
    "df_E.to_csv('Friends_E_whole.tsv', sep='\\t')\n",
    "df_O.to_csv('Friends_O_whole.tsv', sep='\\t')\n",
    "df_N.to_csv('Friends_N_whole.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertConfig, BertForSequenceClassification\n",
    "df_A['tokens'] = [tokenizer.encode(sent, add_special_tokens=False,\n",
    "            pad_to_max_length=False) for sent in df_A['sent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    711.000000\n",
       "mean      16.269433\n",
       "std        5.708456\n",
       "min        3.250000\n",
       "25%       12.267857\n",
       "50%       15.500000\n",
       "75%       19.522727\n",
       "max       42.250000\n",
       "Name: uttr_len, dtype: float64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A['tokens_len'] = df_A['tokens'].apply(lambda x:len(x))\n",
    "df_A['num_uttr'] = df_A['dialog_state'].apply(lambda x:len(x))\n",
    "df_A['uttr_len'] = df_A['tokens_len']/df_A['num_uttr']\n",
    "df_A['uttr_len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_A['utterance'][0]))\n",
    "\n",
    "cnt = 0\n",
    "for i in df_A['utterance']:\n",
    "    cnt += 1\n",
    "    if type(i) != str:\n",
    "        print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Monica', ' What are you doing?'], ['Phoebe', \" No, I'm really okay with this. Y'know why? 'Cause look at them, and I made that, so... I know it's gonna be like a million times harder to give up a baby but, oh my God, it's gonna feel like a million times better, right? I wanna do this. (To Frank and Alice) I wanna carry your baby.\"], ['Alice', \" (shocked) Oh! Oh! Oh! Thank you so much! You don't know what this means to us! Oh!\"], ['Frank', \" Oh my God, I think I'm gonna cry!\"], ['Monica', \" It's gonna be so great.\"], ['Phoebe Sr.', \" (entering) Hi! What's going on?\"]]\n"
     ]
    }
   ],
   "source": [
    "print(df_A.iloc[581]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/zhiyuan/ENTER/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2173: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,IterableDataset\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer\n",
    "from transformers import BertTokenizer, BertConfig, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import re\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "\n",
    "\n",
    "df_A = pd.read_csv('Friends_A_whole.tsv', sep='\\t')\n",
    "sents = [tokenizer.encode(sent, add_special_tokens=True, max_length=64, \\\n",
    "                pad_to_max_length=True) for sent in df_A['text']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>scene_id</th>\n",
       "      <th>text</th>\n",
       "      <th>character</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>dialog_state</th>\n",
       "      <th>sent</th>\n",
       "      <th>utterance</th>\n",
       "      <th>context</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01_e01_c01</td>\n",
       "      <td>[['Ross Geller', \" No!! Okay?! Why does everyo...</td>\n",
       "      <td>Joey Tribbiani</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>No!! Okay?! Why does everyone keep fixating o...</td>\n",
       "      <td>Alright Ross, look. You're feeling a lot of ...</td>\n",
       "      <td>No!! Okay?! Why does everyone keep fixating ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>01_e01_c02</td>\n",
       "      <td>[['Monica Geller', \" Now I'm guessing that he ...</td>\n",
       "      <td>Chandler Bing</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Now I'm guessing that he bought her the big p...</td>\n",
       "      <td>(imitating the characters) Tuna or egg salad...</td>\n",
       "      <td>Now I'm guessing that he bought her the big ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>01_e01_c04</td>\n",
       "      <td>[['Ross Geller', \" (squatting and reading the ...</td>\n",
       "      <td>Chandler Bing</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>(squatting and reading the instructions) I'm ...</td>\n",
       "      <td>It's a beautiful thing.  I would have to say...</td>\n",
       "      <td>(squatting and reading the instructions) I'm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>01_e01_c05</td>\n",
       "      <td>[['Monica Geller', ' Oh my God!'], ['Paul', \" ...</td>\n",
       "      <td>Paul</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 1, 0, 1, 0]</td>\n",
       "      <td>Oh my God! I know, I know, I'm such an idiot....</td>\n",
       "      <td>I know, I know, I'm such an idiot. I guess I...</td>\n",
       "      <td>Oh my God!  My brother's going through that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>01_e01_c08</td>\n",
       "      <td>[['Paul', ' Ever since she walked out on me, I...</td>\n",
       "      <td>Monica Geller</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "      <td>Ever since she walked out on me, I, uh... Wha...</td>\n",
       "      <td>What?..... What, you wanna spell it out with...</td>\n",
       "      <td>Ever since she walked out on me, I, uh...  N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    scene_id                                               text  \\\n",
       "0           0  01_e01_c01  [['Ross Geller', \" No!! Okay?! Why does everyo...   \n",
       "1           1  01_e01_c02  [['Monica Geller', \" Now I'm guessing that he ...   \n",
       "2           2  01_e01_c04  [['Ross Geller', \" (squatting and reading the ...   \n",
       "3           3  01_e01_c05  [['Monica Geller', ' Oh my God!'], ['Paul', \" ...   \n",
       "4           4  01_e01_c08  [['Paul', ' Ever since she walked out on me, I...   \n",
       "\n",
       "        character  cAGR                             dialog_state  \\\n",
       "0  Joey Tribbiani     1                 [0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "1   Chandler Bing     1                    [0, 0, 0, 0, 0, 0, 0]   \n",
       "2   Chandler Bing     0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "3            Paul     1                          [0, 1, 0, 1, 0]   \n",
       "4   Monica Geller     1           [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
       "\n",
       "                                                sent  \\\n",
       "0   No!! Okay?! Why does everyone keep fixating o...   \n",
       "1   Now I'm guessing that he bought her the big p...   \n",
       "2   (squatting and reading the instructions) I'm ...   \n",
       "3   Oh my God! I know, I know, I'm such an idiot....   \n",
       "4   Ever since she walked out on me, I, uh... Wha...   \n",
       "\n",
       "                                           utterance  \\\n",
       "0    Alright Ross, look. You're feeling a lot of ...   \n",
       "1    (imitating the characters) Tuna or egg salad...   \n",
       "2    It's a beautiful thing.  I would have to say...   \n",
       "3    I know, I know, I'm such an idiot. I guess I...   \n",
       "4    What?..... What, you wanna spell it out with...   \n",
       "\n",
       "                                             context  labels  \n",
       "0    No!! Okay?! Why does everyone keep fixating ...       1  \n",
       "1    Now I'm guessing that he bought her the big ...       1  \n",
       "2    (squatting and reading the instructions) I'm...       0  \n",
       "3    Oh my God!  My brother's going through that ...       1  \n",
       "4    Ever since she walked out on me, I, uh...  N...       1  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (640 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96801\n",
      "27669\n",
      "5346\n",
      "2796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from transformers import BertTokenizer, BertConfig, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n",
    "\n",
    "VAD_Lexicons = pd.read_csv('NRC-VAD-Lexicon-Aug2018Release/NRC-VAD-Lexicon.txt', sep='\\t')\n",
    "VAD_dict = {}\n",
    "for r in VAD_Lexicons.iterrows():\n",
    "    VAD_dict[r[1]['Word']] = [r[1]['Valence'], r[1]['Arousal'], r[1]['Dominance']]\n",
    "VAD_dict = VAD_dict\n",
    "\n",
    "\n",
    "cnt = 0\n",
    "raw_match = 0\n",
    "match = 0\n",
    "\n",
    "token_set = set([])\n",
    "matched_set = set([])\n",
    "\n",
    "\n",
    "for i,r in df_A.iterrows():\n",
    "    raw_sent = r['sent'] \n",
    "    sent = raw_sent\n",
    "    try:\n",
    "        sent_ids = tokenizer.encode(raw_sent, add_special_tokens=False)\n",
    "        for i in sent_ids:\n",
    "            tmp = tokenizer.decode(i).replace(' ', '')\n",
    "            if not tmp in string.punctuation:\n",
    "                token_set.add(tmp)\n",
    "                cnt += 1\n",
    "                try:\n",
    "                    VAD_dict[tmp]\n",
    "                    matched_set.add(tmp)\n",
    "                    match += 1\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        print(r['sent'])\n",
    "print(cnt)\n",
    "print(match)\n",
    "\n",
    "print(len(token_set))\n",
    "print(len(matched_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]\n",
      "no\n",
      "okay\n",
      "why\n",
      "does\n",
      "everyone\n",
      "keep\n",
      "fix\n",
      "##ating\n",
      "on\n",
      "that\n",
      "she\n",
      "didn\n",
      "t\n",
      "know\n",
      "how\n",
      "should\n",
      "i\n",
      "know\n",
      "sometimes\n",
      "i\n",
      "wish\n",
      "i\n",
      "was\n",
      "a\n",
      "lesbian\n",
      "they\n",
      "all\n",
      "stare\n",
      "at\n",
      "him\n",
      "did\n",
      "i\n",
      "say\n",
      "that\n",
      "out\n",
      "loud\n",
      "i\n",
      "told\n",
      "mom\n",
      "and\n",
      "dad\n",
      "last\n",
      "night\n",
      "they\n",
      "seemed\n",
      "to\n",
      "take\n",
      "it\n",
      "pretty\n",
      "well\n",
      "oh\n",
      "really\n",
      "so\n",
      "that\n",
      "hysterical\n",
      "phone\n",
      "call\n",
      "i\n",
      "got\n",
      "from\n",
      "a\n",
      "woman\n",
      "at\n",
      "sobbing\n",
      "3\n",
      "00\n",
      "a\n",
      "m\n",
      "i\n",
      "ll\n",
      "never\n",
      "have\n",
      "grandchildren\n",
      "i\n",
      "ll\n",
      "never\n",
      "have\n",
      "grandchildren\n",
      "was\n",
      "what\n",
      "a\n",
      "wrong\n",
      "number\n",
      "sorry\n",
      "alright\n",
      "ross\n",
      "look\n",
      "you\n",
      "re\n",
      "feeling\n",
      "a\n",
      "lot\n",
      "of\n",
      "pain\n",
      "right\n",
      "now\n",
      "you\n",
      "re\n",
      "angry\n",
      "you\n",
      "re\n",
      "hurting\n",
      "can\n",
      "i\n",
      "tell\n",
      "you\n",
      "what\n",
      "the\n",
      "answer\n",
      "is\n",
      "strip\n",
      "joint\n",
      "c\n",
      "mon\n",
      "you\n",
      "re\n",
      "single\n",
      "have\n",
      "some\n",
      "hormones\n",
      "i\n",
      "don\n",
      "t\n",
      "want\n",
      "to\n",
      "be\n",
      "single\n",
      "okay\n",
      "i\n",
      "just\n",
      "i\n",
      "just\n",
      "i\n",
      "just\n",
      "wanna\n",
      "be\n",
      "married\n",
      "again\n",
      "[SEP]\n"
     ]
    }
   ],
   "source": [
    "sent_ids = tokenizer.encode(df_A['sent'][0], add_special_tokens=True)\n",
    "for i in sent_ids:\n",
    "    tmp = tokenizer.decode(i).replace(' ', '')\n",
    "    if not tmp in string.punctuation:\n",
    "        print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Ross Geller', \" No!! Okay?! Why does everyone keep fixating on that? She didn't know, how should I know?\"], ['Chandler Bing', ' Sometimes I wish I was a lesbian... (They all stare at him.) Did I say that out loud?'], ['Ross Geller', ' I told mom and dad last night, they seemed to take it pretty well.'], ['Monica Geller', ' Oh really, so that hysterical phone call I got from a woman at sobbing 3:00 A.M., \"I\\'ll never have grandchildren, I\\'ll never have grandchildren.\" was what? A wrong number?'], ['Ross Geller', ' Sorry.'], ['Joey Tribbiani', \" Alright Ross, look. You're feeling a lot of pain right now. You're angry. You're hurting. Can I tell you what the answer is?\"], ['Joey Tribbiani', \" Strip joint! C'mon, you're single! Have some hormones!\"], ['Ross Geller', \" I don't want to be single, okay? I just... I just- I just wanna be married again!\"]]\n"
     ]
    }
   ],
   "source": [
    "print(df_A.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joey Tribbiani\n",
      "  Alright Ross, look. You're feeling a lot of pain right now. You're angry. You're hurting. Can I tell you what the answer is?  Strip joint! C'mon, you're single! Have some hormones!\n"
     ]
    }
   ],
   "source": [
    "print(df_A.iloc[0]['character'])\n",
    "print(df_A.iloc[0]['utterance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  No!! Okay?! Why does everyone keep fixating on that? She didn't know, how should I know?  Sometimes I wish I was a lesbian... (They all stare at him.) Did I say that out loud?  I told mom and dad last night, they seemed to take it pretty well.  Oh really, so that hysterical phone call I got from a woman at sobbing 3:00 A.M., \"I'll never have grandchildren, I'll never have grandchildren.\" was what? A wrong number?  Sorry.  I don't want to be single, okay? I just... I just- I just wanna be married again!\n"
     ]
    }
   ],
   "source": [
    "print(df_A.iloc[0]['context'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8157\n",
      "11.472573839662447\n",
      "8157\n"
     ]
    }
   ],
   "source": [
    "lengths = [len(i) for i in df_A['dialog_state']]\n",
    "print(sum(lengths))\n",
    "print(sum(lengths)/float(len(lengths)))\n",
    "cnt = 0\n",
    "for i,r in df_O.iterrows():\n",
    "    cnt +=  len(r['text']) \n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VAD_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-74a86b2b21fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mVAD_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mget_vad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAD_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-74a86b2b21fa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mVAD_scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mget_vad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAD_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'VAD_dict' is not defined"
     ]
    }
   ],
   "source": [
    "def get_vad(VAD_dict, sents, tokenizer):\n",
    "    VAD_scores = []\n",
    "    for sent in sents:\n",
    "        w_list = re.sub(r'[^\\w\\s\\[\\]]','',tokenizer.decode(sent)).split()\n",
    "        v_score, a_score, d_score = 0, 0, 0\n",
    "        for word in w_list:\n",
    "            try:\n",
    "                v_score += VAD_dict[word][0]\n",
    "                a_score += VAD_dict[word][1]\n",
    "                d_score += VAD_dict[word][2]\n",
    "            except:\n",
    "                v_score += 0\n",
    "                a_score += 0\n",
    "                d_score += 0\n",
    "\n",
    "        v_score/=float(len(w_list))\n",
    "        a_score/=float(len(w_list))\n",
    "        d_score/=float(len(w_list))\n",
    "        VAD_scores.append([v_score, a_score, d_score])\n",
    "    return VAD_scores\n",
    "\n",
    "[get_vad(VAD_dict,sent) for sent in contexts]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
